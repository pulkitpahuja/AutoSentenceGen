{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/exoper/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (15,30,31,32,36,37,38,42,43,44,45,46,47,50,51,52,56,57,58,59,60,61,62,63,64,65,66,67) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    Read a great interview with Donald Trump that ...\n",
       "1    Congratulations to Evan Lysacek for being nomi...\n",
       "2    I was on The View this morning. We talked abou...\n",
       "3    Tomorrow night's episode of The Apprentice del...\n",
       "4    Donald Trump Partners with TV1 on New Reality ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = pd.read_csv('/home/exoper/Documents/data/trump_tw.csv')\n",
    "ds.text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read a great interview with Donald Trump that appeared in The New York Times Magazine: http://tinyurl.com/qsx4o6 Congratulations to Evan Lysacek for being nominated SI sportsman of the year. He's a great guy, and he has my vote!  #EvanForSI I was on The View this morning. We talked about The Apprentice. Tonight's episode is a great one--tough, exciting and surprising. 10 pm/NBC Tomorrow night's episode of The Apprentice delivers excitement at QVC along with appearances by Isaac Mizrahi and Cathie Black. 10 pm on NBC Donald Trump Partners with TV1 on New Reality Series Entitled, Omarosa's Ultimate Merger: http://tinyurl.com/yk5m3lc I'll be appearing on Larry King Live for his final show, Thursday night at 9 p.m., CNN. Larry's been on TV for 25 years... I'll be on The Late Show with David Letterman tonight--be sure to tune in for a great show. 11:30 pm on CBS. Watch the Miss Universe competition LIVE from the Bahamas - Sunday, 8/23 @ 9pm (ET) on NBC: http://tinyurl.com/mrzad9 Watch video\n"
     ]
    }
   ],
   "source": [
    "# Take all the text together\n",
    "\n",
    "data = ' '.join([ix for ix in ds.text])\n",
    "print (data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ğŸ˜œ', '\\\\', 'âŒ', 'ãƒ©', 'ÄŸ', 'ğŸ˜„', 'ã–', 'ğŸ‘—', 'ğŸ˜‰', 'ğŸ’™', 'ğŸ˜±', 'ğŸ™Œ', 'ğŸ˜', 'y', 'd', 'æ­´', 'ã¦', 'R', 'Ã¡', '\\u200e', 'L', '-', 'J', 'çµ†', '×“', 'g', 'c', 'â›³', 'ğŸ“ˆ', '_', 'ãƒ—', '5', 'T', 'ğŸ˜Š', 'ğŸ’•', 'ğŸ“¸', 'Â»', 'Ã¯', 'â˜‘', 'ğŸ‘¢', 'ğŸ‡°', '\\r', 'ğŸ’ƒ', '2', 'e', 'ğŸ’¨', 'ğŸ‡¨', 'n', 'ğŸŒº', 'âœ…', 'é–“', 'ğŸ‡³', 'ğŸ‡²', 'ã¨', 'ã€‚', 'ğŸ¤–', 'ğŸ˜', '\\U0010fc00', 'çµ±', 'B', 'ğŸ“·', 'p', 'ã‚‹', 'è¨ª', 'ğŸ˜°', 'Y', 'ãƒ³', 'w', 'â‚¬', 'ğŸ’—', 'ğŸ˜£', 'k', 'A', 'Â´', 'C', 'ğŸŒ¹', '`', 'ğŸ¢', 'ğŸ¦ƒ', 'D', 'Â«', 'æº', 'â˜‰', 'ğŸ˜‚', 'ç›Ÿ', 'ï¼²', 'çš„', 'ãƒŠ', 'ğŸ’¤', '×–', 'â˜€', 'ã¾', 'â—', 'ğŸ’', 'ã”', 'ğŸ‡¦', 'ğŸ‡´', 'Äº', 'ğŸ»', '{', '.', 'ğŸ‘†', 'ç•Œ', '\"', 'Â®', '*', '[', 'ğŸ‘ˆ', 'ğŸ‡º', 'ğŸ‘', 'ğŸ˜”', 'o', 'ğŸ˜³', 'x', 'ğŸš‚', 'ğŸ‘‘', 'ã€', 'ğŸ‡µ', 'ã‚¸', 'Ãº', 'â€¦', 'ã„', 'ç¤º', 'U', 'ç±³', '8', '7', 'Å', 'ğŸ·', 'âš¡', 'ğŸ’', 'â˜', 'O', 'ğŸŒš', 'ğŸ˜¢', 'P', 'h', '1', 'é ˜', 'ğŸš¨', 'ğŸ“‰', 'r', 'ğŸ§', 'ğŸˆ', 'â€¼', 'â˜†', 'ğŸŒ', 'åŠŸ', '%', 'ğŸ‡®', 'ğŸ‘‹', 'ğŸ†', '&', 'Ã©', '@', '\\u200b', ':', 'ğŸ‘”', 'ğŸ¾', 'ã‚’', 'åŒ', 'Ã¨', 'æ—¥', 'i', '$', 'âš¾', 'âœŒ', 'ğŸ˜†', 'ãŠ', 'ğŸ‘€', 'ğŸ˜´', 'ãŒ', 'ğŸ˜¡', 'Ã‰', 'l', 'â¡', 'æˆ', ';', 'é•', 'ğŸ˜“', 'Ã¸', 'Ã­', 'â€˜', 'ğŸ™…', '×', '#', 'ğŸ¥', 'ğŸ˜‘', '}', 'â¤', 'ğŸ‡±', 'ğŸ’‹', 'ğŸ¼', 'ğŸ‘Œ', 'å¤§', ']', 'ğŸ‰', 'ğŸ»', 'ã‚ˆ', 'å•', \"'\", 'ã—', 'j', 'ã‚Š', 'm', 'ãŸ', 'ğŸ«', 'ã€Š', 'ğŸ“–', 't', '9', 'â€™', 'W', '×™', 'ğŸ’°', '~', 'ã', 'ãƒ«', 'ğŸ’š', 'ğŸ˜', 'ã', '6', 'â¬…', 'ğŸ˜©', 'ã†', 'â™¥', 'ã‚¢', '\\u200f', 'ğŸ˜', 'ğŸ’¦', 'ğŸ’ª', 'âœ”', ' ', 'â™¡', 'ğŸ’¯', '/', 'a', 'ãƒ‰', 'N', 'ğŸ‘¿', 'ğŸ¬', 'ã™', 'ã®', 'ğŸ’”', 'âœ¨', 'á»…', '\\xa0', 'Â£', 'ğŸ”¥', 'â€', 'Ã±', ')', 'â˜¹', 'ğŸ‡·', 'ğŸ‘‰', 'ğŸ‘', 'ğŸ‡ª', 'ğŸ˜ƒ', 'ğŸ‡«', 'Z', 'z', 'q', 'â˜…', '4', 'ğŸ˜’', 'ğŸŒ', 'ğŸ˜…', 'â€“', 'ã', 'ğŸ˜¬', 'ğŸš€', '!', 'ã', 'Ã³', 'ğŸ’¥', 'ğŸ‘', 'ï¼´', 'âœŠ', 'â€¢', 'V', '(', 'Q', '×ª', 'â€•', 'â˜º', 'â˜', 'K', 'ğŸ½', 'â†”', '|', 'ä¸–', 'â€²', 'ğŸ˜', 'å½“', 'ğŸˆ', 'v', 'ğŸ‡¸', '=', 'X', 'â¬‡', 'ğŸ—½', 'ğŸ‡¯', 'ï¸', 's', 'ğŸ‡»', '×', '3', 'ğŸ’œ', 'â€”', 'u', 'E', 'åˆ', 'â€œ', '×§', 'Ä±', '\\x92', 'ğŸ‘', 'â„¢', 'b', '0', 'ãƒˆ', 'â˜', 'ğŸ”…', 'ãª', '\\n', '×—', 'ğŸ¤”', 'ç¥ˆ', 'ã§', 'ğŸ˜˜', 'M', '+', 'ğŸ“º', 'ã«', 'ğŸ‘š', 'ã“', 'I', 'ğŸ˜‡', 'Âº', 'Ã¢', '?', 'H', 'æœ¬', 'ğŸ‘Š', 'ã¯', 'G', 'F', 'f', 'ğŸ’˜', ',', 'ğŸ™', 'âœˆ', 'S', 'å²', 'ã‚'}\n",
      "355\n"
     ]
    }
   ],
   "source": [
    "print (set(data))\n",
    "print (len(set(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Vocab\n",
    "vocab = list(set(data))\n",
    "\n",
    "i2c, c2i = {}, {}\n",
    "#print(len(vocab))\n",
    "for idx, chx in enumerate(vocab):\n",
    "    i2c[idx] = chx\n",
    "    c2i[chx] = idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 17, 355)\n"
     ]
    }
   ],
   "source": [
    "def get_onehot(x):\n",
    "    # Take input a string and convert to one-hot encoding\n",
    "    vec_size = len(c2i.keys())\n",
    "    n_seq = len(x)\n",
    "    data = np.zeros((1, n_seq, vec_size))\n",
    "    \n",
    "    # For each element in the list\n",
    "    for ix in range(n_seq):\n",
    "        curr_char = x[ix]\n",
    "        oh_index = c2i[curr_char]\n",
    "        # print ix, curr_char, oh_index\n",
    "        data[:, ix, oh_index] = 1\n",
    "    return data\n",
    "\n",
    "print (get_onehot('this is my string').shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 112, 355)\n",
      "(1, 127, 355)\n",
      "(1, 139, 355)\n",
      "(1, 140, 355)\n",
      "(1, 116, 355)\n",
      "(1, 122, 355)\n",
      "(1, 108, 355)\n",
      "(1, 117, 355)\n",
      "(1, 115, 355)\n",
      "(1, 102, 355)\n"
     ]
    }
   ],
   "source": [
    "for ix in ds.text[:10]:\n",
    "    print (get_onehot(ix).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharNN(nn.Module):\n",
    "    def __init__(self, in_shape=None, out_shape=None, hidden_shape=None):\n",
    "        super(CharNN, self).__init__()\n",
    "        self.in_shape = in_shape\n",
    "        self.out_shape = out_shape\n",
    "        self.hidden_shape = hidden_shape\n",
    "        self.n_layers = 1\n",
    "        \n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=self.in_shape,\n",
    "            hidden_size=self.hidden_shape,\n",
    "            num_layers=self.n_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.out = nn.Linear(self.hidden_shape, self.out_shape)\n",
    "    \n",
    "    def forward(self, x, h):\n",
    "        r_out, h_state = self.rnn(x, h)\n",
    "        \n",
    "        outs = []\n",
    "        for ix in range(r_out.size(1)):\n",
    "            current_out = F.softmax(self.out(r_out[:, ix, :]))\n",
    "            outs.append(current_out)\n",
    "        return torch.stack(outs, dim=1), h_state\n",
    "    \n",
    "    def predict(self, char, h=None, top_k=None):\n",
    "        if h is None:\n",
    "            h = self.init_hidden(1, gpu=False)\n",
    "        \n",
    "        x = get_onehot(char)\n",
    "        out, h = self.forward(torch.FloatTensor(x), h)\n",
    "        \n",
    "        p = out.data\n",
    "        if top_k is None:\n",
    "            top_ch = np.arange(self.out_shape)\n",
    "        else:\n",
    "            p, top_ch = p.topk(top_k)\n",
    "            top_ch = top_ch.numpy().squeeze()\n",
    "        \n",
    "        p = p.numpy().squeeze()\n",
    "        char = np.random.choice(top_ch, p=p/p.sum())\n",
    "        return i2c[char], h\n",
    "    \n",
    "    def init_hidden(self, batch_size, gpu=False):\n",
    "        if gpu:\n",
    "            return (Variable(torch.zeros(self.n_layers, batch_size, self.hidden_shape).cuda()),\n",
    "                    Variable(torch.zeros(self.n_layers, batch_size, self.hidden_shape)).cuda())\n",
    "        return (Variable(torch.zeros(self.n_layers, batch_size, self.hidden_shape)),\n",
    "                Variable(torch.zeros(self.n_layers, batch_size, self.hidden_shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/exoper/.local/lib/python3.5/site-packages/torch/cuda/__init__.py:97: UserWarning: \n",
      "    Found GPU0 GeForce 940MX which is of cuda capability 5.0.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn % (d, name, major, capability[1]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CharNN(\n",
      "  (rnn): LSTM(174, 256, batch_first=True)\n",
      "  (out): Linear(in_features=256, out_features=174, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = CharNN(in_shape=174, out_shape=174, hidden_shape=256)\n",
    "model.cuda()\n",
    "print (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/shubham/all_projects/CB/Summer_2018/data/checkpoints/text_gen/model_256h_epoch_38.ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-3e8a5e0f547d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/shubham/all_projects/CB/Summer_2018/data/checkpoints/text_gen/model_256h_epoch_38.ckpt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/shubham/all_projects/CB/Summer_2018/data/checkpoints/text_gen/model_256h_epoch_38.ckpt'"
     ]
    }
   ],
   "source": [
    "# Load the weights\n",
    "model.load_state_dict(torch.load('/home/shubham/all_projects/CB/Summer_2018/data/checkpoints/text_gen/model_256h_epoch_38.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict('a', top_k=20)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-d8a0b0d9bcd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;31m# print pred.squeeze().shape, y.shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-95a3993f3de2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, h)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mr_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0mflat_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         func = self._backend.RNN(\n\u001b[1;32m    192\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    139\u001b[0m             raise RuntimeError(\n\u001b[1;32m    140\u001b[0m                 'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(\n\u001b[0;32m--> 141\u001b[0;31m                     fn.input_size, input.size(-1)))\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_input_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fn' is not defined"
     ]
    }
   ],
   "source": [
    "# Set to train mode\n",
    "# model.cuda()\n",
    "model.train()\n",
    "N = 5000\n",
    "\n",
    "for epoch in range(50):\n",
    "    total_loss = 0\n",
    "    # For each sequence\n",
    "    for qx in range(N):\n",
    "        seqx = ds.text[qx]\n",
    "        h_state = model.init_hidden(1)\n",
    "        input_seq = seqx[:-1]\n",
    "        target_seq = seqx[1:]\n",
    "        \n",
    "        x = Variable(torch.FloatTensor(get_onehot(input_seq)), requires_grad=True)# .cuda()\n",
    "        y = Variable(torch.LongTensor(get_onehot(target_seq).argmax(2)))# .cuda()\n",
    "        \n",
    "        model.zero_grad()\n",
    "        pred, h_state = model.forward(x, h_state)\n",
    "        # print pred.squeeze().shape, y.shape\n",
    "        loss = criterion(pred.squeeze(), y.squeeze())\n",
    "        \n",
    "        # optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # gradient clipping to solve exploding/vanishing grads\n",
    "        # clip = 5.0\n",
    "        # nn.utils.clip_grad_norm(net.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss\n",
    "        if qx%(N/5) == 0:\n",
    "            print ('Loss: {} at Epoch: {} | Seq: {}'.format(loss, epoch, qx))\n",
    "        \n",
    "    print( \"Overall Average Loss: {} at Epoch: {}\".format(total_loss / float(N), epoch))\n",
    "    \n",
    "    # Save model checkpoints\n",
    "    if epoch % 10 == 0:\n",
    "        torch.save(model.state_dict(), \"./data/checkpoints/text_gen/model_256h_epoch_{}.ckpt\".format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "or @Markettorial @Markettoristing @Marketanders @Markettorian and an amarion and an amarian and an amas and an amarinate and an amasting and an amarian and an amater and an amaring and an amas and an amarian and an amarical and an amas and an amasting and an amarinate and an amaster and an amasting and an amarian and an amappathing and an amappathing and an amarian and an amasting and an amapart and an amaring and an amasting and an amarian and an amas and an amasting and an amasping and and an amarian and an amas and an amasting and an amarinate and an amasting and an amarian and an amasting and an amarical and an amas and an amasting and an amasting and an amarian and an amarical and an amasting and an amasting and an amas and an amas and an amasting and an amarian and an amas and an amasping and and an amaring and an amasting and an amasting and an amasting and an amasting and an amarian and an amas and an amas and an amasting and an amas and an amas and an amasting and an amasting a\n"
     ]
    }
   ],
   "source": [
    "sentence = 'o'\n",
    "model.cpu()\n",
    "h_s = model.init_hidden(1, gpu=False)\n",
    "for ix in range(1000):\n",
    "    ctx = sentence[-1]\n",
    "    out, h = model.predict(ctx, h=h_s, top_k=100)\n",
    "    h_s = (h[0].data, h[1].data)\n",
    "    \n",
    "    sentence += out\n",
    "print sentence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
